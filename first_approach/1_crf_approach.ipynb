{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Named Entity Recognition with Conditional Random Fields",
   "id": "497bc04a48fd4ffe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Install Required Libraries",
   "id": "d26ccc189bca08a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:00:24.059375Z",
     "start_time": "2024-04-28T19:59:59.081950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install -q spacy\n",
    "!python -m spacy download ru_core_news_sm\n",
    "!pip install -q sklearn-crfsuite"
   ],
   "id": "abd07710fd093698",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting ru-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.7.0/ru_core_news_sm-3.7.0-py3-none-any.whl (15.3 MB)\n",
      "                                              0.0/15.3 MB ? eta -:--:--\n",
      "                                              0.0/15.3 MB ? eta -:--:--\n",
      "                                             0.0/15.3 MB 320.0 kB/s eta 0:00:48\n",
      "                                             0.0/15.3 MB 262.6 kB/s eta 0:00:58\n",
      "                                             0.0/15.3 MB 262.6 kB/s eta 0:00:58\n",
      "                                             0.1/15.3 MB 252.2 kB/s eta 0:01:01\n",
      "                                             0.1/15.3 MB 327.7 kB/s eta 0:00:47\n",
      "                                             0.1/15.3 MB 344.8 kB/s eta 0:00:44\n",
      "                                             0.1/15.3 MB 343.4 kB/s eta 0:00:45\n",
      "                                             0.2/15.3 MB 471.4 kB/s eta 0:00:32\n",
      "                                             0.2/15.3 MB 533.8 kB/s eta 0:00:29\n",
      "                                             0.3/15.3 MB 570.1 kB/s eta 0:00:27\n",
      "                                             0.4/15.3 MB 712.2 kB/s eta 0:00:21\n",
      "     -                                       0.5/15.3 MB 850.4 kB/s eta 0:00:18\n",
      "     -                                       0.6/15.3 MB 950.3 kB/s eta 0:00:16\n",
      "     --                                       0.8/15.3 MB 1.1 MB/s eta 0:00:13\n",
      "     --                                       1.0/15.3 MB 1.3 MB/s eta 0:00:11\n",
      "     ---                                      1.2/15.3 MB 1.6 MB/s eta 0:00:09\n",
      "     ---                                      1.4/15.3 MB 1.7 MB/s eta 0:00:09\n",
      "     ----                                     1.5/15.3 MB 1.8 MB/s eta 0:00:08\n",
      "     ----                                     1.7/15.3 MB 1.9 MB/s eta 0:00:08\n",
      "     -----                                    2.0/15.3 MB 2.0 MB/s eta 0:00:07\n",
      "     -----                                    2.1/15.3 MB 2.1 MB/s eta 0:00:07\n",
      "     -----                                    2.3/15.3 MB 2.2 MB/s eta 0:00:06\n",
      "     ------                                   2.5/15.3 MB 2.3 MB/s eta 0:00:06\n",
      "     -------                                  2.7/15.3 MB 2.4 MB/s eta 0:00:06\n",
      "     -------                                  2.8/15.3 MB 2.4 MB/s eta 0:00:06\n",
      "     --------                                 3.1/15.3 MB 2.5 MB/s eta 0:00:05\n",
      "     --------                                 3.3/15.3 MB 2.5 MB/s eta 0:00:05\n",
      "     --------                                 3.4/15.3 MB 2.6 MB/s eta 0:00:05\n",
      "     ---------                                3.6/15.3 MB 2.6 MB/s eta 0:00:05\n",
      "     ---------                                3.7/15.3 MB 2.6 MB/s eta 0:00:05\n",
      "     ----------                               3.8/15.3 MB 2.6 MB/s eta 0:00:05\n",
      "     ----------                               4.0/15.3 MB 2.6 MB/s eta 0:00:05\n",
      "     ----------                               4.1/15.3 MB 2.6 MB/s eta 0:00:05\n",
      "     -----------                              4.2/15.3 MB 2.6 MB/s eta 0:00:05\n",
      "     -----------                              4.4/15.3 MB 2.6 MB/s eta 0:00:05\n",
      "     -----------                              4.5/15.3 MB 2.7 MB/s eta 0:00:05\n",
      "     ------------                             4.7/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     ------------                             4.8/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     ------------                             5.0/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     -------------                            5.1/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     -------------                            5.2/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     --------------                           5.4/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     --------------                           5.5/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     --------------                           5.6/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     ---------------                          5.8/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     ---------------                          5.9/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     ---------------                          6.1/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     ----------------                         6.2/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     ----------------                         6.3/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     ----------------                         6.5/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     -----------------                        6.6/15.3 MB 2.8 MB/s eta 0:00:04\n",
      "     -----------------                        6.7/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     -----------------                        6.8/15.3 MB 2.7 MB/s eta 0:00:04\n",
      "     ------------------                       7.1/15.3 MB 2.8 MB/s eta 0:00:03\n",
      "     ------------------                       7.2/15.3 MB 2.8 MB/s eta 0:00:03\n",
      "     -------------------                      7.3/15.3 MB 2.7 MB/s eta 0:00:03\n",
      "     -------------------                      7.5/15.3 MB 2.8 MB/s eta 0:00:03\n",
      "     --------------------                     7.7/15.3 MB 2.8 MB/s eta 0:00:03\n",
      "     --------------------                     7.7/15.3 MB 2.8 MB/s eta 0:00:03\n",
      "     --------------------                     8.0/15.3 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------------                    8.1/15.3 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------------                    8.2/15.3 MB 2.8 MB/s eta 0:00:03\n",
      "     ----------------------                   8.4/15.3 MB 2.8 MB/s eta 0:00:03\n",
      "     ----------------------                   8.6/15.3 MB 2.8 MB/s eta 0:00:03\n",
      "     ----------------------                   8.7/15.3 MB 2.8 MB/s eta 0:00:03\n",
      "     -----------------------                  8.9/15.3 MB 2.8 MB/s eta 0:00:03\n",
      "     -----------------------                  9.0/15.3 MB 2.8 MB/s eta 0:00:03\n",
      "     -----------------------                  9.1/15.3 MB 2.8 MB/s eta 0:00:03\n",
      "     ------------------------                 9.3/15.3 MB 2.9 MB/s eta 0:00:03\n",
      "     ------------------------                 9.5/15.3 MB 2.9 MB/s eta 0:00:03\n",
      "     -------------------------                9.6/15.3 MB 2.9 MB/s eta 0:00:02\n",
      "     -------------------------                9.8/15.3 MB 2.9 MB/s eta 0:00:02\n",
      "     -------------------------                9.9/15.3 MB 2.9 MB/s eta 0:00:02\n",
      "     --------------------------               10.1/15.3 MB 2.9 MB/s eta 0:00:02\n",
      "     --------------------------               10.2/15.3 MB 2.9 MB/s eta 0:00:02\n",
      "     ---------------------------              10.4/15.3 MB 3.2 MB/s eta 0:00:02\n",
      "     ---------------------------              10.5/15.3 MB 3.3 MB/s eta 0:00:02\n",
      "     ---------------------------              10.6/15.3 MB 3.3 MB/s eta 0:00:02\n",
      "     ----------------------------             10.9/15.3 MB 3.3 MB/s eta 0:00:02\n",
      "     ----------------------------             11.0/15.3 MB 3.3 MB/s eta 0:00:02\n",
      "     -----------------------------            11.1/15.3 MB 3.3 MB/s eta 0:00:02\n",
      "     -----------------------------            11.4/15.3 MB 3.3 MB/s eta 0:00:02\n",
      "     ------------------------------           11.5/15.3 MB 3.3 MB/s eta 0:00:02\n",
      "     ------------------------------           11.6/15.3 MB 3.2 MB/s eta 0:00:02\n",
      "     -------------------------------          11.8/15.3 MB 3.3 MB/s eta 0:00:02\n",
      "     -------------------------------          11.9/15.3 MB 3.3 MB/s eta 0:00:02\n",
      "     -------------------------------          12.1/15.3 MB 3.2 MB/s eta 0:00:01\n",
      "     --------------------------------         12.3/15.3 MB 3.3 MB/s eta 0:00:01\n",
      "     --------------------------------         12.4/15.3 MB 3.3 MB/s eta 0:00:01\n",
      "     --------------------------------         12.6/15.3 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------        12.7/15.3 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------        12.9/15.3 MB 3.2 MB/s eta 0:00:01\n",
      "     ----------------------------------       13.1/15.3 MB 3.2 MB/s eta 0:00:01\n",
      "     ----------------------------------       13.1/15.3 MB 3.2 MB/s eta 0:00:01\n",
      "     -----------------------------------      13.4/15.3 MB 3.2 MB/s eta 0:00:01\n",
      "     -----------------------------------      13.6/15.3 MB 3.2 MB/s eta 0:00:01\n",
      "     -----------------------------------      13.6/15.3 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------------     13.9/15.3 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------------     14.0/15.3 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------------     14.1/15.3 MB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------------    14.4/15.3 MB 3.2 MB/s eta 0:00:01\n",
      "     --------------------------------------   14.6/15.3 MB 3.3 MB/s eta 0:00:01\n",
      "     --------------------------------------   14.6/15.3 MB 3.2 MB/s eta 0:00:01\n",
      "     --------------------------------------   14.8/15.3 MB 3.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  15.0/15.3 MB 3.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  15.1/15.3 MB 3.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 15.3/15.3 MB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from ru-core-news-sm==3.7.0) (3.7.4)\n",
      "Requirement already satisfied: pymorphy3>=1.0.0 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from ru-core-news-sm==3.7.0) (2.0.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (0.7.2)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (2.4.417150.4580142)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sokos\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.10.13)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (67.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\sokos\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.26.1)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\sokos\\appdata\\roaming\\python\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sokos\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sokos\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sokos\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sokos\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\sokos\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.1.0)\n",
      "\u001B[38;5;2m[+] Download and installation successful\u001B[0m\n",
      "You can now load the package via spacy.load('ru_core_news_sm')\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load Libraries and SpaCy Model",
   "id": "56ded7b16135b824"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:00:24.074560Z",
     "start_time": "2024-04-28T20:00:24.060375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import zipfile\n",
    "import sklearn_crfsuite\n",
    "import spacy"
   ],
   "id": "2ffb80e3cf10dc31",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:00:24.842581Z",
     "start_time": "2024-04-28T20:00:24.075561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load Russian spaCy model\n",
    "nlp = spacy.load('ru_core_news_sm')"
   ],
   "id": "d2e1fca5e2409ce1",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Declare Functions",
   "id": "17ad7a90527e29d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:00:24.858361Z",
     "start_time": "2024-04-28T20:00:24.843581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\" \n",
    "    Load JSONL data from a file.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): The path to the file to load.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of dictionaries containing the data.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n"
   ],
   "id": "44351a02daad3b5d",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:00:24.873419Z",
     "start_time": "2024-04-28T20:00:24.859362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_training_data(data):\n",
    "    \"\"\" \n",
    "    Process training data with entity labels, preparing for feature extraction. \n",
    "    \n",
    "    Parameters:\n",
    "    data (list): A list of dictionaries containing the data.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of tuples containing the tokens and labels for each document.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "    \n",
    "    # Process each document in the data\n",
    "    for item in data:\n",
    "        doc = nlp(item['sentences'])\n",
    "        labels = ['O'] * len(doc)\n",
    "        \n",
    "        # Set labels for tokens that are part of named entities\n",
    "        for start, end, label in item.get('ners', []):\n",
    "            for token in doc:\n",
    "                if token.idx >= start and token.idx + len(token.text) <= end:\n",
    "                    labels[token.i] = label\n",
    "        tokens_labels = [(token, labels[token.i]) for token in doc]\n",
    "        processed_data.append(tokens_labels)\n",
    "    return processed_data\n"
   ],
   "id": "c37c49c6f9576879",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:00:24.888546Z",
     "start_time": "2024-04-28T20:00:24.874419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_test_data(data):\n",
    "    \"\"\" \n",
    "    Process test data, preparing for feature extraction without labels.\n",
    "    \n",
    "    Parameters:\n",
    "    data (list): A list of dictionaries containing the data.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of tuples containing the tokens and labels for each document.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "    for item in data:\n",
    "        doc = nlp(item['senences'])  # Typo in the key name\n",
    "        document_id = item['id']\n",
    "        tokens_labels = [(token, 'O', document_id) for token in doc]\n",
    "        processed_data.append(tokens_labels)\n",
    "    return processed_data\n"
   ],
   "id": "4e6b27fd0b37e85e",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:00:24.904567Z",
     "start_time": "2024-04-28T20:00:24.889546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_features(doc):\n",
    "    \"\"\" \n",
    "    Extract features from each token in a document. \n",
    "    \n",
    "    Parameters:\n",
    "    doc (list): A list of tokens in the document.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of dictionaries containing the features for each token.\n",
    "    \"\"\"\n",
    "    return [word2features(token, i) for i, token in enumerate(doc)]\n"
   ],
   "id": "95e6f0ca9c06a253",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:00:24.919326Z",
     "start_time": "2024-04-28T20:00:24.904567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def word2features(token, i):\n",
    "    \"\"\" \n",
    "    Generate features from a token. \n",
    "    \n",
    "    Parameters:\n",
    "    token (spacy.Token): The token to generate features for.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing the features for the token.\n",
    "    \"\"\"\n",
    "    # Features for the token\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': token.text.lower(),\n",
    "        'word[-3:]': token.text[-3:],\n",
    "        'word[-2:]': token.text[-2:],\n",
    "        'word.isupper()': token.text.isupper(),\n",
    "        'word.istitle()': token.text.istitle(),\n",
    "        'word.isdigit()': token.text.isdigit(),\n",
    "        'BOS': i == 0,\n",
    "        'EOS': i == len(token.doc) - 1,\n",
    "    }\n",
    "    if i > 0:\n",
    "        features.update({\n",
    "            '-1:word.lower()': token.doc[i-1].text.lower(),\n",
    "            '-1:word.istitle()': token.doc[i-1].text.istitle(),\n",
    "            '-1:word.isupper()': token.doc[i-1].text.isupper(),\n",
    "        })\n",
    "    if i < len(token.doc) - 1:\n",
    "        features.update({\n",
    "            '+1:word.lower()': token.doc[i+1].text.lower(),\n",
    "            '+1:word.istitle()': token.doc[i+1].text.istitle(),\n",
    "            '+1:word.isupper': token.doc[i+1].text.isupper(),\n",
    "        })\n",
    "    return features\n"
   ],
   "id": "b543f72c87d5f60c",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:00:24.934839Z",
     "start_time": "2024-04-28T20:00:24.920326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_predictions_to_jsonl(data, predictions, filename='test.jsonl'):\n",
    "    \"\"\" \n",
    "    Save predictions in JSONL format suitable for submission. \n",
    "    \n",
    "    Parameters:\n",
    "    data (list): A list of tuples containing the tokens and labels for each document.\n",
    "    predictions (list): A list of predicted labels for each document.\n",
    "    filename (str): The name of the file to save the predictions to.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    # Combine the data and predictions\n",
    "    for data_entry, pred_labels in zip(data, predictions):\n",
    "        document_id = data_entry[0][2]\n",
    "        result = {'id': document_id, 'ners': []}\n",
    "        # Extract the named entities from the predictions\n",
    "        for (token, _, doc_id), label in zip(data_entry, pred_labels):\n",
    "            if label != 'O':\n",
    "                start_idx = token.idx\n",
    "                end_idx = start_idx + len(token.text) - 1\n",
    "                result['ners'].append([start_idx, end_idx, label])\n",
    "        results.append(result)\n",
    "    \n",
    "    # Save the results to a JSONL file\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for line in results:\n",
    "            json.dump(line, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n"
   ],
   "id": "af20606680c5a4be",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:00:24.950360Z",
     "start_time": "2024-04-28T20:00:24.936342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def zip_file(input_filename, output_filename='test.zip'):\n",
    "    \"\"\" \n",
    "    Zip the specified file.\n",
    "    \n",
    "    Parameters:\n",
    "    input_filename (str): The name of the file to zip.\n",
    "    output_filename (str): The name of the output zip file.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(output_filename, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "        zf.write(input_filename)\n"
   ],
   "id": "d113b6804b957438",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Train and Predict with CRF",
   "id": "8802f24332c4adad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:01:02.154734Z",
     "start_time": "2024-04-28T20:00:24.951360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load and process training data\n",
    "train_data = process_training_data(load_data('../data/train.jsonl'))\n",
    "X_train = [extract_features([t[0] for t in doc]) for doc in train_data]\n",
    "y_train = [[t[1] for t in doc] for doc in train_data]"
   ],
   "id": "d9cb15a7080d5160",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:01:45.301760Z",
     "start_time": "2024-04-28T20:01:02.154734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train CRF model\n",
    "crf = sklearn_crfsuite.CRF(algorithm='l2sgd')\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ],
   "id": "c825d9383b850b",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:01:49.674348Z",
     "start_time": "2024-04-28T20:01:45.302761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load and process test data\n",
    "test_data = process_test_data(load_data('../data/test.jsonl'))\n",
    "X_test = [extract_features([t[0] for t in doc]) for doc in test_data]"
   ],
   "id": "22313bdde7a34532",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:01:49.769308Z",
     "start_time": "2024-04-28T20:01:49.675349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make predictions\n",
    "y_pred = crf.predict(X_test)"
   ],
   "id": "89fba7578b583785",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:01:49.801096Z",
     "start_time": "2024-04-28T20:01:49.770309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save predictions to JSONL file\n",
    "save_predictions_to_jsonl(test_data, y_pred)\n",
    "zip_file('test.jsonl')"
   ],
   "id": "dd24cb319854742d",
   "outputs": [],
   "execution_count": 96
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
